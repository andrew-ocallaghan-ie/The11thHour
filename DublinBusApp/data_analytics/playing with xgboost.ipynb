{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/katerooney/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>LineID</th>\n",
       "      <th>Direction</th>\n",
       "      <th>Journey_Pattern_ID</th>\n",
       "      <th>Timeframe</th>\n",
       "      <th>Vehicle_Journey_ID</th>\n",
       "      <th>Lon</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Vehicle_ID</th>\n",
       "      <th>...</th>\n",
       "      <th>End_Stop</th>\n",
       "      <th>Stops_To_Travel</th>\n",
       "      <th>Time_To_Travel_Dirty</th>\n",
       "      <th>Time_To_Travel</th>\n",
       "      <th>Scheduled_Speed_Per_Stop</th>\n",
       "      <th>time_bins</th>\n",
       "      <th>Rain</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Wind_Speed</th>\n",
       "      <th>Hour_Of_Day_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>143</td>\n",
       "      <td>1352181949000000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>40001</td>\n",
       "      <td>2012-11-06</td>\n",
       "      <td>5332</td>\n",
       "      <td>-6.264970</td>\n",
       "      <td>53.402534</td>\n",
       "      <td>43034</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>52</td>\n",
       "      <td>2637000000</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1.016949</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>177</td>\n",
       "      <td>1352182129000000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>40001</td>\n",
       "      <td>2012-11-06</td>\n",
       "      <td>5332</td>\n",
       "      <td>-6.264059</td>\n",
       "      <td>53.396149</td>\n",
       "      <td>43034</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>52</td>\n",
       "      <td>2457000000</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.016949</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>196</td>\n",
       "      <td>1352182208000000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>40001</td>\n",
       "      <td>2012-11-06</td>\n",
       "      <td>5332</td>\n",
       "      <td>-6.263807</td>\n",
       "      <td>53.392265</td>\n",
       "      <td>43034</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>52</td>\n",
       "      <td>2378000000</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1.016949</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>229</td>\n",
       "      <td>1352182391000000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>40001</td>\n",
       "      <td>2012-11-06</td>\n",
       "      <td>5332</td>\n",
       "      <td>-6.265748</td>\n",
       "      <td>53.380424</td>\n",
       "      <td>43034</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>52</td>\n",
       "      <td>2195000000</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.016949</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>247</td>\n",
       "      <td>1352182484000000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>40001</td>\n",
       "      <td>2012-11-06</td>\n",
       "      <td>5317</td>\n",
       "      <td>-6.225992</td>\n",
       "      <td>53.327579</td>\n",
       "      <td>43032</td>\n",
       "      <td>...</td>\n",
       "      <td>59</td>\n",
       "      <td>19</td>\n",
       "      <td>802000000</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.016949</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         Timestamp  LineID  Direction  Journey_Pattern_ID  \\\n",
       "0         143  1352181949000000       4          0               40001   \n",
       "1         177  1352182129000000       4          0               40001   \n",
       "2         196  1352182208000000       4          0               40001   \n",
       "3         229  1352182391000000       4          0               40001   \n",
       "4         247  1352182484000000       4          0               40001   \n",
       "\n",
       "    Timeframe  Vehicle_Journey_ID       Lon        Lat  Vehicle_ID  \\\n",
       "0  2012-11-06                5332 -6.264970  53.402534       43034   \n",
       "1  2012-11-06                5332 -6.264059  53.396149       43034   \n",
       "2  2012-11-06                5332 -6.263807  53.392265       43034   \n",
       "3  2012-11-06                5332 -6.265748  53.380424       43034   \n",
       "4  2012-11-06                5317 -6.225992  53.327579       43032   \n",
       "\n",
       "       ...        End_Stop  Stops_To_Travel  Time_To_Travel_Dirty  \\\n",
       "0      ...              57               52            2637000000   \n",
       "1      ...              57               52            2457000000   \n",
       "2      ...              57               52            2378000000   \n",
       "3      ...              57               52            2195000000   \n",
       "4      ...              59               19             802000000   \n",
       "\n",
       "  Time_To_Travel  Scheduled_Speed_Per_Stop  time_bins  Rain  Temperature  \\\n",
       "0           43.0                  1.016949          4   0.0          2.2   \n",
       "1           40.0                  1.016949          4   0.0          2.2   \n",
       "2           39.0                  1.016949          4   0.0          2.2   \n",
       "3           36.0                  1.016949          4   0.0          2.2   \n",
       "4           13.0                  1.016949          1   0.0          2.2   \n",
       "\n",
       "   Wind_Speed  Hour_Of_Day_y  \n",
       "0        10.0             23  \n",
       "1        10.0             23  \n",
       "2        10.0             23  \n",
       "3        10.0             23  \n",
       "4        10.0             23  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The ultimate target feature: time from one stop to another\n",
    "\n",
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date, datetime\n",
    "from patsy import dmatrices\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "%matplotlib inline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import export_graphviz, DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn import preprocessing\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.tree import export_graphviz \n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.externals import joblib \n",
    "from statsmodels.formula.api import ols\n",
    "from numpy import loadtxt\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Read csv file into a dataframe.\n",
    "df = pd.read_csv('csv_data/beta4.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0 Model Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Random Forest Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#journey pattern ID here just represents direction - we can switch for direction for user input\n",
    "#took out RDS event as not right to simply include one event - not consist for all events at RDS in Jan\n",
    "#stop order is essentially the number of times that bus stopped - we will not know that\n",
    "#speed - uses the stop order to work out time travelling (includes time journey started) / stop order (position) - we will not know that\n",
    "#therefore is the best we can do in real time is to record the journey times/distances as speeds for each scheduled run?\n",
    "y, X = dmatrices('Time_To_Travel ~ Day_Of_Week + Time_Bin_Start +  Scheduled_Speed_Per_Stop + Wind_Speed +  Temperature  + Holiday + Stops_To_Travel + Stop_Sequence', df, return_type=\"dataframe\") \n",
    "y = np.ravel(y)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[[\"Day_Of_Week\" , \"Time_Bin_Start\" , \"Scheduled_Speed_Per_Stop\", \"Wind_Speed\", \"Temperature\", \"Holiday\", \"Stops_To_Travel\", \"Stop_Sequence\"]]\n",
    "Y = df['Time_To_Travel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: :  (68575, 56)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/katerooney/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:129: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "encoded_x = None\n",
    "for i in range(0, X.shape[1]):\n",
    "\tlabel_encoder = LabelEncoder()\n",
    "\tfeature = label_encoder.fit_transform(X[[\"Day_Of_Week\"]])\n",
    "\tfeature = feature.reshape(X.shape[0], 1)\n",
    "\tonehot_encoder = OneHotEncoder(sparse=False)\n",
    "\tfeature = onehot_encoder.fit_transform(feature)\n",
    "\tif encoded_x is None:\n",
    "\t\tencoded_x = feature\n",
    "\telse:\n",
    "\t\tencoded_x = np.concatenate((encoded_x, feature), axis=1)\n",
    "print(\"X shape: : \", encoded_x.shape)\n",
    "# encode string class values as integers\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder = label_encoder.fit(Y)\n",
    "label_encoded_y = label_encoder.transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/katerooney/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:129: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: :  (68575, 584)\n"
     ]
    }
   ],
   "source": [
    "encoded_x = None\n",
    "for i in range(0, X.shape[1]):\n",
    "\tlabel_encoder = LabelEncoder()\n",
    "\tfeature = label_encoder.fit_transform(X[[\"Time_Bin_Start\"]])\n",
    "\tfeature = feature.reshape(X.shape[0], 1)\n",
    "\tonehot_encoder = OneHotEncoder(sparse=False)\n",
    "\tfeature = onehot_encoder.fit_transform(feature)\n",
    "\tif encoded_x is None:\n",
    "\t\tencoded_x = feature\n",
    "\telse:\n",
    "\t\tencoded_x = np.concatenate((encoded_x, feature), axis=1)\n",
    "print(\"X shape: : \", encoded_x.shape)\n",
    "# encode string class values as integers\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder = label_encoder.fit(Y)\n",
    "label_encoded_y = label_encoder.transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7\n",
    "test_size = 0.33\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=33) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
       "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
       "       objective='multi:softprob', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=0, silent=True, subsample=1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "scaler = preprocessing.StandardScaler().fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "pipeline = make_pipeline(preprocessing.StandardScaler(), \n",
    "                         RandomForestRegressor(n_estimators=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "hyperparameters = { 'randomforestregressor__max_features' : ['auto', 'sqrt', 'log2'],\n",
    "                  'randomforestregressor__max_depth': [None, 5, 3, 1]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "clf = GridSearchCV(pipeline, hyperparameters, cv=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = [round(value) for value in y_pred]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "pred = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 11.89%\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "r2_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good, closer to 1 the better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good, closer to 0 the better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This saves the model for later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(clf, '../flask_app/static/rf_regressor.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can then be reloaded to be used in the flask app. As seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf2 = joblib.load('../flask_app/static/rf_regressor.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = list(clf2.predict(X_test))\n",
    "predictions\n",
    "\n",
    "modified=[]\n",
    "\n",
    "for i in predictions:\n",
    "    modified.append(i)\n",
    "# print(modified)\n",
    "\n",
    "X_test[\"Prediction\"]=0\n",
    "X_test[\"Prediction\"]=modified\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=100, max_features='auto', oob_score=True, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To Do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Date is in the model as a variable making significant impact as cannot group random forest by dates - to confirm why it makes an impact (improves score about 7% but we should  understand is this equiv to groupby or coincidence or a proxy for events).\n",
    "\n",
    "Getting a memory error with feature importance so for now using the linear results to guide - issue with rain: clearly important - we know that - and humidity is important, but no rain columns are making any impact. See commented out code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'feature': X_train.columns, 'importance':rfc.feature_importances_})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision tree for single tree - not going to work here but gives visual of the tree structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier(criterion='entropy', max_depth=4,min_samples_leaf=5)\n",
    "clf = clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tree.export_graphviz(clf, out_file='tree.dot', feature_names = X_train.columns)\n",
    "!dot -Tpng tree.dot > tree.png\n",
    "from IPython.display import Image \n",
    "Image(filename='tree.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "def measure_performance(X,y,clf, show_accuracy=True,show_classification_report=True, show_confussion_matrix=True):\n",
    "    \n",
    "    y_pred=clf.predict(X)\n",
    "    \n",
    "    if show_accuracy:\n",
    "        print (\"accuracy\",metrics.accuracy_score(y, y_pred))\n",
    "        \n",
    "    if show_classification_report:\n",
    "        print (\"classification\",metrics.classification_report(y,y_pred))\n",
    "            \n",
    "    if show_confussion_matrix:\n",
    "        print (\"confusion matrix\",metrics.confusion_matrix(y,y_pred))\n",
    "        \n",
    "measure_performance(X_train,y_train,clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K nearest neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "from numpy.random import permutation\n",
    "\n",
    "# Randomly shuffle the index of df.\n",
    "random_indices = permutation(df.index)\n",
    "# Set a cutoff for how many items we want in the test set (in this case 1/3 of the items)\n",
    "test_cutoff = math.floor(len(df)/3)\n",
    "# Generate the test set by taking the first 1/3 of the randomly shuffled indices.\n",
    "test = df.loc[random_indices[1:test_cutoff]]\n",
    "# Generate the train set with the rest of the data.\n",
    "train = df.loc[random_indices[test_cutoff:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_columns = ['speed', 'stop_order','DayOfWeek', 'HourOfDay', 'MinsOfHour', 'Direction_north']\n",
    "y_column = ['time_bins']\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "# Create the knn model.\n",
    "# Look at the five closest neighbors.\n",
    "knn = KNeighborsRegressor(n_neighbors=5)\n",
    "# Fit the model on the training data.\n",
    "knn.fit(train[x_columns], train[y_column])\n",
    "# Make point predictions on the test set using the fit model.\n",
    "predictions = knn.predict(test[x_columns])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the actual values for the test set.\n",
    "actual = test[y_column]\n",
    "\n",
    "# Compute the mean squared error of our predictions.\n",
    "mse = (((predictions - actual) ** 2).sum()) / len(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as sm\n",
    "\n",
    "# Train all continuous features.\n",
    "check1 = sm.ols(formula='Time_To_Travel ~ Day_Of_Week + Time_Bin_Start + Scheduled_Speed_Per_Stop +  Temperature + Wind_Speed +  Stops_To_Travel + Stop_Sequence', data=df).fit()\n",
    "# Print the weights learned for each feature.\n",
    "print(check1.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Model with Bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training the model with original selection of four features:\n",
    "\n",
    "logreg = sm.logit(formula='Time_To_Travel ~ Day_Of_Week + Time_Bin_Start + Scheduled_Speed_Per_Stop +  Temperature + Wind_Speed +  Stops_To_Travel + Stop_Sequence', data=df).fit()\n",
    "\n",
    "# Print the weights learned for each feature.\n",
    "print(logreg.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
