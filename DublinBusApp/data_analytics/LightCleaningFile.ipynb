{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andy\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#import sections something to cover all bases\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from patsy import dmatrices\n",
    "import matplotlib.patches as mpatches\n",
    "import statsmodels.formula.api as sm\n",
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from statsmodels.formula.api import logit\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import time\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "import threading\n",
    "\n",
    "import cleaning_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# pool = Pool(processes=2) # initialize the Pool.\n",
    "# months=[\"Jan\", \"Nov\"]\n",
    "# result = pool.map(cleaning_functions.re_construct, months)       # map f to the data using the Pool of processes to do the work \n",
    "# pool.close() # No more processes\n",
    "# pool.join()\n",
    "# print(\"Result: \", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# pool = Pool(processes=2) # initialize the Pool.\n",
    "# months=[\"Jan\", \"Nov\"]\n",
    "# result = pool.map(cleaning_functions.complete_extraction, months)       # map f to the data using the Pool of processes to do the work \n",
    "# pool.close() # No more processes\n",
    "# pool.join()\n",
    "# print(\"Result: \", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_speed_check():\n",
    "    sequence_dataframe = pd.read_csv(\"route_seq.csv\",\n",
    "                                     encoding = \"latin1\",\n",
    "                                     header = 0,\n",
    "                                     index_col = None,\n",
    "                                     converters = {\"LineID\":str,\n",
    "                                                   \"Stop_ID\":str,\n",
    "                                                   \"Stop_Sequence\": str})\n",
    "    \n",
    "    \n",
    "    sequence_dataframe = sequence_dataframe[[\"LineID\",\n",
    "                                             \"Stop_ID\",\n",
    "                                             \"Stop_Sequence\",\n",
    "                                             \"Destination\"]]\n",
    "\n",
    "    LIDS = set( sequence_dataframe.LineID.unique())\n",
    "\n",
    "    for LID in LIDS:\n",
    "\n",
    "        DIRS = set (sequence_dataframe[sequence_dataframe[\"LineID\"] == LID].Destination.unique())\n",
    "        for DIR in DIRS:\n",
    "            SIDS = set (sequence_dataframe[(sequence_dataframe[\"LineID\"] == LID) &\\\n",
    "                                           (sequence_dataframe[\"Destination\"]==DIR)].Stop_ID.unique())\n",
    "            for SID in SIDS:\n",
    "                SEQS = set(sequence_dataframe[(sequence_dataframe[\"LineID\"]==LID) &\\\n",
    "                                              (sequence_dataframe[\"Destination\"]==DIR) &\\\n",
    "                                              (sequence_dataframe[\"Stop_ID\"] == SID)].Stop_Sequence.unique())\n",
    "                if len(SEQS) != 1:\n",
    "                    print(\"Problem:\", LID,\":\", DIR, SID, SEQS)\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "make_speed_check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Only the FINAL outputs appear as cell output, but you can track progress in the ipy terminal. (if you activate jupyter notebook withing terminal you will see outputs such as print statements running in each function.) When multiprocessing  you can expect 4 outputs to occur simultaneously. \n",
    "\n",
    "e.g.\n",
    "reconstucting x\n",
    "reconstucting y\n",
    "reconstucting a\n",
    "reconstucting b\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def join_months(iterator):\n",
    "    print(\"joining routes : \")\n",
    "    \n",
    "    \n",
    "    path = os.path.join(os.getcwd(), \"NovJan_routes\")\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    \n",
    "    Nov_path = os.path.join(os.getcwd(), \"Nov_routes\")\n",
    "    Jan_path = os.path.join(os.getcwd(), \"Jan_routes\")\n",
    "    contents = os.listdir(Nov_path)\n",
    "    \n",
    "    \n",
    "    for file in iterator:\n",
    "        if file != '.DS_Store':\n",
    "            Nov_path_to_file = os.path.join(Nov_path, file)\n",
    "            Nov_dataframe = pd.read_hdf(Nov_path_to_file)\n",
    "            \n",
    "            Jan_path_to_file = os.path.join(Jan_path, file)\n",
    "            Jan_dataframe = pd.read_hdf(Jan_path_to_file)\n",
    "            \n",
    "            Jan_dataframe, Nov_dataframe = Jan_dataframe.align(Nov_dataframe, axis=1)\n",
    "            Combined_dataframe = pd.concat([Jan_dataframe,Nov_dataframe])\n",
    "            \n",
    "        \n",
    "            write_address = os.path.join(path,'x' + file)\n",
    "            Combined_dataframe.to_hdf(write_address, key=\"moo\", mode=\"w\")\n",
    "\n",
    "    return 'success'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result:  ['success']\n",
      "Wall time: 10.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pool = Pool(processes=2) # initialize the Pool.\n",
    "Nov_path = os.path.join(os.getcwd(),\"Nov_routes\")\n",
    "contents = os.listdir(Nov_path)\n",
    "total = len(contents)\n",
    "iterators=[contents[:total//2],\n",
    "           contents[total//2:]\n",
    "          ]\n",
    "\n",
    "result = pool.map(cleaning_functions.join_months, iterators )       # map f to the data using the Pool of processes to do the work \n",
    "pool.close() # No more processes\n",
    "pool.join()\n",
    "print(\"Result: \", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#open data\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
