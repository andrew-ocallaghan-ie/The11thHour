{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/katerooney/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# The ultimate target feature: time from one stop to another\n",
    "\n",
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date, datetime\n",
    "from patsy import dmatrices\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "%matplotlib inline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import export_graphviz, DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn import preprocessing\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.externals import joblib \n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Read csv file into a dataframe.\n",
    "df = pd.read_csv('csv_data/route4.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Rename column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.rename(columns={'Timeframe': 'Start_date'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Dropping duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=df.drop_duplicates(keep='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Dropping constant columns or columns with missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.drop('Direction', axis=1)\n",
    "df = df.drop('Unnamed: 0', axis=1)\n",
    "df = df.drop('Congestion', axis=1)\n",
    "df[df.Journey_Pattern_ID == 'null']\n",
    "df = df[df['Journey_Pattern_ID'] != '00040002']\n",
    "df = df[df['Journey_Pattern_ID'] != '00041002']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Remove rows where bus is not at stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.loc[(df != 0).all(axis=1), :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Group to normalise time & remove rows where bus idle at stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create empty column which will hold normalised time\n",
    "df['normal_time'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create empty column which will hold the stop order\n",
    "df['stop_order'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grouped_df = df.groupby(['Vehicle_Journey_ID', 'Start_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_time(df):\n",
    "    \"\"\"Normalise the time for each journey\"\"\"\n",
    "    for i in range(df['Timestamp'].size):\n",
    "        df['normal_time'].values[i] = (df['Timestamp'].values[i] - df['Timestamp'].values[0]) / 1000000\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "norm_gb = grouped_df.apply(normalize_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grouped_df = norm_gb.groupby(['Vehicle_Journey_ID', 'Start_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_idle_at_stop(df):\n",
    "    df = df.drop_duplicates(subset='Stop_ID', keep='first')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "norm_gb = grouped_df.apply(remove_idle_at_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/katerooney/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: 'Vehicle_Journey_ID' is both a column name and an index level.\n",
      "Defaulting to column but this will raise an ambiguity error in a future version\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/katerooney/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: 'Start_date' is both a column name and an index level.\n",
      "Defaulting to column but this will raise an ambiguity error in a future version\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "grouped_df = norm_gb.groupby(['Vehicle_Journey_ID', 'Start_date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Add new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[\"Time\"] = pd.to_datetime(df['Timestamp']*1000, unit=\"ns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['HourOfDay'] = df['Time'].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['MinsOfHour'] = df['Time'].dt.minute\n",
    "df['MinsOfHour30'] = np.where((df['MinsOfHour'] > 30), 1, 0)\n",
    "df['MinsOfHour15'] = np.where((df['MinsOfHour'] > 15), 1, 0)\n",
    "df['MinsOfHour45'] = np.where((df['MinsOfHour'] > 45), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['Time_bin_xxx'] =df.HourOfDay.astype('str') + df.MinsOfHour15.astype('str')+ df.MinsOfHour30.astype('str') + df.MinsOfHour45.astype('str')\n",
    "df['Time_bin_xxx']=df['Time_bin_xxx'].astype('int')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['DayOfWeek'] = df['Time'].dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Direction'] = np.where((df['Journey_Pattern_ID'] == '00041001'), 1,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0 Merge Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Merge bus stop info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_routes = pd.read_csv('csv_data/Route_4_stops.csv', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_routes['Stop_ID']=df_all_routes['Stop_ID'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_routes = df_all_routes[['Stop_ID','Stop_name','Stop_sequence']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, df_routes, on=['Stop_ID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.0 Remove and categories columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Drop missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df[df['Journey_Pattern_ID'] != 'null']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Drop columns no longer needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.drop('Lat', axis=1)\n",
    "df = df.drop('Lon', axis=1)\n",
    "df = df.drop('Block_ID', axis=1)\n",
    "df = df.drop('Operator', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Create time to destination feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['end_time'] = df.groupby(['Vehicle_Journey_ID', 'Start_date'])['Timestamp'].transform(max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['start_time'] = df.groupby(['Vehicle_Journey_ID', 'Start_date'])['Timestamp'].transform(min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['start_stop'] = df.groupby(['Vehicle_Journey_ID', 'Start_date'])['Stop_sequence'].transform(min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['max_stop_sequence'] = df.groupby(['Direction'])['Stop_sequence'].transform(max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['end_stop'] = df.groupby(['Vehicle_Journey_ID', 'Start_date'])['Stop_sequence'].transform(max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['stops_travelled'] = ((df['end_stop'] - df['start_stop']) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['scheduled__overall_journey_time']=60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>LineID</th>\n",
       "      <th>Journey_Pattern_ID</th>\n",
       "      <th>Start_date</th>\n",
       "      <th>Vehicle_Journey_ID</th>\n",
       "      <th>Delay</th>\n",
       "      <th>Vehicle_ID</th>\n",
       "      <th>Stop_ID</th>\n",
       "      <th>At_Stop</th>\n",
       "      <th>normal_time</th>\n",
       "      <th>...</th>\n",
       "      <th>end_stop</th>\n",
       "      <th>stops_travelled</th>\n",
       "      <th>scheduled__overall_journey_time</th>\n",
       "      <th>journey_time</th>\n",
       "      <th>time_travelling</th>\n",
       "      <th>time_to_travel</th>\n",
       "      <th>mins_late</th>\n",
       "      <th>late</th>\n",
       "      <th>speed_journey_full</th>\n",
       "      <th>speed_trip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22617154.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>00040001</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>15475</td>\n",
       "      <td>-8</td>\n",
       "      <td>43046</td>\n",
       "      <td>7113</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>54</td>\n",
       "      <td>60</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>-7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.868852</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22617366.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>00040001</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>15488</td>\n",
       "      <td>102</td>\n",
       "      <td>43040</td>\n",
       "      <td>7113</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>54</td>\n",
       "      <td>60</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.065574</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22618478.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>00040001</td>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>4905</td>\n",
       "      <td>223</td>\n",
       "      <td>43036</td>\n",
       "      <td>7113</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>54</td>\n",
       "      <td>60</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.065574</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22618479.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>00040001</td>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>4905</td>\n",
       "      <td>223</td>\n",
       "      <td>43036</td>\n",
       "      <td>7113</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>54</td>\n",
       "      <td>60</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.065574</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22618490.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>00040001</td>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>4951</td>\n",
       "      <td>44</td>\n",
       "      <td>43039</td>\n",
       "      <td>7113</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>54</td>\n",
       "      <td>60</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1.114754</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Timestamp  LineID Journey_Pattern_ID  Start_date  Vehicle_Journey_ID  \\\n",
       "0  22617154.0     4.0           00040001  2013-01-01               15475   \n",
       "1  22617366.0     4.0           00040001  2013-01-01               15488   \n",
       "2  22618478.0     4.0           00040001  2013-01-02                4905   \n",
       "3  22618479.0     4.0           00040001  2013-01-02                4905   \n",
       "4  22618490.0     4.0           00040001  2013-01-02                4951   \n",
       "\n",
       "   Delay  Vehicle_ID Stop_ID  At_Stop  normal_time     ...      end_stop  \\\n",
       "0     -8       43046    7113        1            0     ...            57   \n",
       "1    102       43040    7113        1            0     ...            57   \n",
       "2    223       43036    7113        1            0     ...            57   \n",
       "3    223       43036    7113        1            0     ...            57   \n",
       "4     44       43039    7113        1            0     ...            57   \n",
       "\n",
       "  stops_travelled  scheduled__overall_journey_time  journey_time  \\\n",
       "0              54                               60          53.0   \n",
       "1              54                               60          65.0   \n",
       "2              54                               60          65.0   \n",
       "3              54                               60          65.0   \n",
       "4              54                               60          68.0   \n",
       "\n",
       "   time_travelling  time_to_travel  mins_late  late  speed_journey_full  \\\n",
       "0              0.0            53.0         -7     0            0.868852   \n",
       "1              0.0            65.0          5     1            1.065574   \n",
       "2              0.0            65.0          5     1            1.065574   \n",
       "3              0.0            65.0          5     1            1.065574   \n",
       "4              0.0            68.0          8     1            1.114754   \n",
       "\n",
       "   speed_trip  \n",
       "0         0.0  \n",
       "1         0.0  \n",
       "2         0.0  \n",
       "3         0.0  \n",
       "4         0.0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['journey_time'] = ((df['end_time'] - df['start_time']) )\n",
    "df['time_travelling'] = ((df['Timestamp'] - df['start_time']) )\n",
    "df['time_to_travel'] = ((df['end_time'] - df['Timestamp'] ) )\n",
    "df['time_travelling'] = pd.to_timedelta(df['time_travelling']*1000, unit=\"ns\").astype('timedelta64[m]')\n",
    "df['time_to_travel'] = pd.to_timedelta(df['time_to_travel']*1000, unit=\"ns\").astype('timedelta64[m]')\n",
    "df['journey_time'] = pd.to_timedelta(df['journey_time']*1000, unit=\"ns\").astype('timedelta64[m]')\n",
    "df['Timestamp'] = pd.to_timedelta(df['Timestamp']*1000, unit=\"ns\").astype('timedelta64[m]')\n",
    "df['mins_late'] = ((df['journey_time'].astype(int) - 60))\n",
    "df['late'] = np.where((df['mins_late'] > 1), 1, 0)\n",
    "df['speed_journey_full']= ((df['journey_time'] / df['max_stop_sequence'].astype('float64') ))\n",
    "df['speed_trip']= ((df['time_travelling'] / df['Stop_sequence'].astype('float64')) )\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['scheduled_speed_per_stop'] = df['scheduled__overall_journey_time']/df['max_stop_sequence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['scheduled_journey_time']=df['scheduled_speed_per_stop'] * df['stops_travelled']\n",
    "df.to_csv('check.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(141263, 38)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Vehicle_Journey_ID'] = pd.to_numeric(df['Vehicle_Journey_ID'], errors='coerce')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bins=[10,20,30,40,50,60,70,80,90,100,110]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5,  6,  7,  8,  4,  3,  0,  9,  1,  2, 10])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['time_bins'] = np.digitize(df.journey_time.values, bins=bins)\n",
    "df.time_bins.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save cleaned dataframe to new CSV file\n",
    "df.to_csv('csv_data/bus_route4_clean.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
